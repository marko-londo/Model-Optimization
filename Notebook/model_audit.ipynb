{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Audit\n",
    "\n",
    "## Dataset\n",
    "\n",
    "You will examine the ProPublica COMPAS dataset, which consists of all criminal defendants who were subject to COMPAS screening in Broward County, Florida, during 2013 and 2014. For each defendant, various information fields (‘features’) were also gathered by ProPublica. Broadly, these fields are related to the defendant’s demographic information (e.g., gender and race), criminal history (e.g., the number of prior offenses) and administrative information about the case (e.g., the case number, arrest date, risk of recidivism predicted by the COMPAS tool). Finally, the dataset also contains information about whether the defendant did actually recidivate or not.\n",
    "\n",
    "The COMPAS score uses answers to 137 questions to assign a risk score to defendants -- essentially a probability of re-arrest. The actual output is two-fold: a risk rating of 1-10 and a \"low\", \"medium\", or \"high\" risk label.\n",
    "\n",
    "Link to dataset: https://github.com/propublica/compas-analysis\n",
    "\n",
    "The file we will analyze is: compas-scores-two-years.csv\n",
    "\n",
    "Link to the ProPublica article:\n",
    "\n",
    "https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing\n",
    "\n",
    "\n",
    "## Project Background and Goals\n",
    "\n",
    "- The COMPAS scores have been shown to have biases against certain racial groups. Analyze the dataset to highlight these biases.  \n",
    "\n",
    "- Based on the features in the COMPAS dataset, train classifiers to predict who will re-offend (hint: no need to use all features, just the ones you find relevant).  Study if your classifiers are more or less fair than the COMPAS classifier. \n",
    "\n",
    "- Build a fair classifier. Is excluding the race from the feature set enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fair Re-Offend Predictor\n",
    "\n",
    "by Steve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "\n",
    "First load the data from the ProPublica repo:\n",
    "https://github.com/propublica/compas-analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>compas_screening_date</th>\n",
       "      <th>sex</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>v_screening_date</th>\n",
       "      <th>in_custody</th>\n",
       "      <th>out_custody</th>\n",
       "      <th>priors_count.1</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>event</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1947-04-18</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>2014-07-07</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982-01-22</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-01-27</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2013-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1991-05-14</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>2013-06-16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-01-21</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>bouthy pierrelouis</td>\n",
       "      <td>bouthy</td>\n",
       "      <td>pierrelouis</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>Male</td>\n",
       "      <td>1973-01-22</td>\n",
       "      <td>43</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>10996</td>\n",
       "      <td>steven butler</td>\n",
       "      <td>steven</td>\n",
       "      <td>butler</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992-07-17</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>2013-11-22</td>\n",
       "      <td>2013-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>10997</td>\n",
       "      <td>malcolm simmons</td>\n",
       "      <td>malcolm</td>\n",
       "      <td>simmons</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993-03-25</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>2014-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>10999</td>\n",
       "      <td>winston gregory</td>\n",
       "      <td>winston</td>\n",
       "      <td>gregory</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>1958-10-01</td>\n",
       "      <td>57</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>11000</td>\n",
       "      <td>farrah jean</td>\n",
       "      <td>farrah</td>\n",
       "      <td>jean</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>1982-11-17</td>\n",
       "      <td>33</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2014-03-08</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>11001</td>\n",
       "      <td>florencia sanmartin</td>\n",
       "      <td>florencia</td>\n",
       "      <td>sanmartin</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>Female</td>\n",
       "      <td>1992-12-18</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7214 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                 name      first         last  \\\n",
       "0         1     miguel hernandez     miguel    hernandez   \n",
       "1         3          kevon dixon      kevon        dixon   \n",
       "2         4             ed philo         ed        philo   \n",
       "3         5          marcu brown      marcu        brown   \n",
       "4         6   bouthy pierrelouis     bouthy  pierrelouis   \n",
       "...     ...                  ...        ...          ...   \n",
       "7209  10996        steven butler     steven       butler   \n",
       "7210  10997      malcolm simmons    malcolm      simmons   \n",
       "7211  10999      winston gregory    winston      gregory   \n",
       "7212  11000          farrah jean     farrah         jean   \n",
       "7213  11001  florencia sanmartin  florencia    sanmartin   \n",
       "\n",
       "     compas_screening_date     sex         dob  age          age_cat  \\\n",
       "0               2013-08-14    Male  1947-04-18   69  Greater than 45   \n",
       "1               2013-01-27    Male  1982-01-22   34          25 - 45   \n",
       "2               2013-04-14    Male  1991-05-14   24     Less than 25   \n",
       "3               2013-01-13    Male  1993-01-21   23     Less than 25   \n",
       "4               2013-03-26    Male  1973-01-22   43          25 - 45   \n",
       "...                    ...     ...         ...  ...              ...   \n",
       "7209            2013-11-23    Male  1992-07-17   23     Less than 25   \n",
       "7210            2014-02-01    Male  1993-03-25   23     Less than 25   \n",
       "7211            2014-01-14    Male  1958-10-01   57  Greater than 45   \n",
       "7212            2014-03-09  Female  1982-11-17   33          25 - 45   \n",
       "7213            2014-06-30  Female  1992-12-18   23     Less than 25   \n",
       "\n",
       "                  race  ...  v_decile_score  v_score_text  v_screening_date  \\\n",
       "0                Other  ...               1           Low        2013-08-14   \n",
       "1     African-American  ...               1           Low        2013-01-27   \n",
       "2     African-American  ...               3           Low        2013-04-14   \n",
       "3     African-American  ...               6        Medium        2013-01-13   \n",
       "4                Other  ...               1           Low        2013-03-26   \n",
       "...                ...  ...             ...           ...               ...   \n",
       "7209  African-American  ...               5        Medium        2013-11-23   \n",
       "7210  African-American  ...               5        Medium        2014-02-01   \n",
       "7211             Other  ...               1           Low        2014-01-14   \n",
       "7212  African-American  ...               2           Low        2014-03-09   \n",
       "7213          Hispanic  ...               4           Low        2014-06-30   \n",
       "\n",
       "      in_custody  out_custody  priors_count.1 start   end event two_year_recid  \n",
       "0     2014-07-07   2014-07-14               0     0   327     0              0  \n",
       "1     2013-01-26   2013-02-05               0     9   159     1              1  \n",
       "2     2013-06-16   2013-06-16               4     0    63     0              1  \n",
       "3            NaN          NaN               1     0  1174     0              0  \n",
       "4            NaN          NaN               2     0  1102     0              0  \n",
       "...          ...          ...             ...   ...   ...   ...            ...  \n",
       "7209  2013-11-22   2013-11-24               0     1   860     0              0  \n",
       "7210  2014-01-31   2014-02-02               0     1   790     0              0  \n",
       "7211  2014-01-13   2014-01-14               0     0   808     0              0  \n",
       "7212  2014-03-08   2014-03-09               3     0   754     0              0  \n",
       "7213  2015-03-15   2015-03-15               2     0   258     0              1  \n",
       "\n",
       "[7214 rows x 53 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv'\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title=\"Profiling Report\")\n",
    "profile\n",
    "```\n",
    "ProfileReport can be helpful to familiarize oneself with the dataset. It can\n",
    "show us correlations within features, null values, duplicates etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "I got rid of difficult columns and then turned categorical features into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
       "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
       "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
       "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
       "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
       "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
       "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
       "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
       "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
       "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
       "       'decile_score.1', 'score_text', 'screening_date',\n",
       "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
       "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
       "       'start', 'end', 'event', 'two_year_recid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id', 'sex', 'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
    "       'juv_misd_count', 'juv_other_count', 'priors_count', 'c_charge_degree', \n",
    "       'is_recid', 'is_violent_recid', 'decile_score.1', 'v_decile_score',\n",
    "       'two_year_recid']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "##### - Features selected that could/should have been dropped:\n",
    "- age: High correlation with age_cat, redundant.\n",
    "- juv_other_count: Not a misdemeanor or felony, ambiguous, probably irrelevant.\n",
    "- decile_score.1: same as decile_score\n",
    "\n",
    "***Edit***\n",
    "I didn't pick up on this until doing my own analysis, but \"is_recid\" and\n",
    "\"two_year_recid\" possess nearly identical values. I was originally operating under the\n",
    "assumption that \"is_recid\" meant they had already recommitted a crime prior to\n",
    "this evaluation, and that the individual performing this analysis didn't\n",
    "drop the feature for that reason. Without further documentation I can't confirm\n",
    "this to be the case, however I believe the feature should be left out to err on\n",
    "the side of caution. This would also explain the near perfect accuracy of the\n",
    "model, as it would imply a data leak.\n",
    "  \n",
    "##### - Features dropped that could have been selected:\n",
    "- r_charge_degree: could be relevant when combined with c_charge_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "sex                 0\n",
       "age                 0\n",
       "age_cat             0\n",
       "race                0\n",
       "juv_fel_count       0\n",
       "decile_score        0\n",
       "juv_misd_count      0\n",
       "juv_other_count     0\n",
       "priors_count        0\n",
       "c_charge_degree     0\n",
       "is_recid            0\n",
       "is_violent_recid    0\n",
       "decile_score.1      0\n",
       "v_decile_score      0\n",
       "two_year_recid      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There didn't seem to be any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['sex','age_cat','race','c_charge_degree'] \n",
    "\n",
    "df = pd.get_dummies(df, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After one hot encoding, redundant columns should be dropped to avoid potential\n",
    "overfitting.\n",
    "For Example: the Female column becomes redundant if Male can only == 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('two_year_recid', axis=1)\n",
    "y = df['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No cross validation, impossible to tell if the model is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "I picked an SVC because I like them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the SVM classifier\n",
    "clf = SVC()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the confusion matrix\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC is a fine model, but can be prone to overfitting.\n",
    "The data should have been scaled. A better solution might\n",
    "have been to start with a simple logistic regression model with cross validation and\n",
    "hyperparameter tuning, and compare those results with the SVC model (and maybe\n",
    "others too) to determine which produces best. With certain models Feature\n",
    "Importance could be implemented to further refine the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "I checked accuracy and did a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9695121951219512\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "```\n",
    "\n",
    "Would be preffered in professional settings for readability and maintainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[951,  54],\n",
       "       [  1, 798]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification report would be helpful to see the precision, recall,\n",
    "f1-score, and support for each class. An AUC-ROC curve would also be insightful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "This is a very good and fair model because it is very accurate and predicts very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrible summary. It is vague, empty, and shows no real supporting metrics or\n",
    "evidence. No actual bias checking was done. Without a classification report we\n",
    "have no idea of the f1-score, precision, recall, etc. No details on what model was\n",
    "used or how it was trained. No mention of validation (as none was used), so we\n",
    "have no idea how the model will perform on new data. There is no context on the\n",
    "problem domain or why and how certain decisions were made regarding the feature\n",
    "engineering. Potential limitations of the model should also be included, as\n",
    "should be recommendations or steps for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Your Turn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations to Improve the Model and Reduce Bias\n",
    "\n",
    "Resampling with SMOTEENN could be helpful in reducing the bias of the model, by\n",
    "increasing the size of the minority classes and removing samples from the\n",
    "majority classes.\n",
    "\n",
    "Another solution would be to simply remove the \"race\" feature altogether.\n",
    "\n",
    "We could also perform a bias audit with [AI Fairness 360](https://ai-fairness-360.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Bias\n",
    "\n",
    "Using a method of your choosing retrieve feature importance for Steve's model\n",
    "\n",
    "Compare predictions between `African-American` and `Caucasian` using a Confusion Matrix or any other tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 5: -0.0008 +/- 0.0008\n",
      "Feature 2: -0.0001 +/- 0.0002\n",
      "Feature 8: -0.0001 +/- 0.0002\n",
      "Feature 11: 0.0000 +/- 0.0000\n",
      "Feature 20: 0.0000 +/- 0.0000\n",
      "Feature 19: 0.0000 +/- 0.0000\n",
      "Feature 18: 0.0000 +/- 0.0000\n",
      "Feature 17: 0.0000 +/- 0.0000\n",
      "Feature 16: 0.0000 +/- 0.0000\n",
      "Feature 15: 0.0000 +/- 0.0000\n",
      "Feature 14: 0.0000 +/- 0.0000\n",
      "Feature 13: 0.0000 +/- 0.0000\n",
      "Feature 22: 0.0000 +/- 0.0000\n",
      "Feature 21: 0.0000 +/- 0.0000\n",
      "Feature 10: 0.0000 +/- 0.0000\n",
      "Feature 9: 0.0000 +/- 0.0000\n",
      "Feature 7: 0.0000 +/- 0.0000\n",
      "Feature 4: 0.0000 +/- 0.0000\n",
      "Feature 3: 0.0000 +/- 0.0000\n",
      "Feature 1: 0.0000 +/- 0.0000\n",
      "Feature 12: 0.0000 +/- 0.0000\n",
      "Feature 0: 0.0019 +/- 0.0018\n",
      "Feature 6: 0.4591 +/- 0.0125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Use permutation_importance as the SVC instance is not linear and there is no\n",
    "# easy way to check for feature importance\n",
    "\n",
    "result = permutation_importance(clf, X_test, y_test, n_repeats=30, random_state=42)\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "# Print the feature importance\n",
    "for i in sorted_idx:\n",
    "    print(f\"Feature {i}: {result.importances_mean[i]:.4f} +/- {result.importances_std[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Caucasian Samples:\n",
      "[[376  11]\n",
      " [  1 233]]\n",
      "\n",
      "Confusion Matrix for African-American Samples:\n",
      "[[414  40]\n",
      " [  0 473]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Subset the true labels and predictions for Caucasian samples\n",
    "y_test_caucasian = y_test[X_test['race_Caucasian'] == 1]\n",
    "y_pred_caucasian = y_pred[X_test['race_Caucasian'] == 1]\n",
    "\n",
    "# Subset the true labels and predictions for African-American samples\n",
    "y_test_aa = y_test[X_test['race_African-American'] == 1]\n",
    "y_pred_aa = y_pred[X_test['race_African-American'] == 1]\n",
    "\n",
    "# Compute confusion matrices\n",
    "confusion_matrix_caucasian = confusion_matrix(y_test_caucasian, y_pred_caucasian)\n",
    "confusion_matrix_aa = confusion_matrix(y_test_aa, y_pred_aa)\n",
    "\n",
    "print(\"Confusion Matrix for Caucasian Samples:\")\n",
    "print(confusion_matrix_caucasian)\n",
    "\n",
    "print(\"\\nConfusion Matrix for African-American Samples:\")\n",
    "print(confusion_matrix_aa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve the Model\n",
    "\n",
    "Implement some/all of your suggestions to make Steve's model better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>two_year_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>African-American</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   sex          age_cat              race  juv_fel_count  juv_misd_count  \\\n",
       "0   1  Male  Greater than 45             Other              0               0   \n",
       "1   3  Male          25 - 45  African-American              0               0   \n",
       "2   4  Male     Less than 25  African-American              0               0   \n",
       "3   5  Male     Less than 25  African-American              0               1   \n",
       "4   6  Male          25 - 45             Other              0               0   \n",
       "\n",
       "   priors_count c_charge_degree  is_recid  is_violent_recid  decile_score.1  \\\n",
       "0             0               F         0                 0               1   \n",
       "1             0               F         1                 1               3   \n",
       "2             4               F         1                 0               4   \n",
       "3             1               F         0                 0               8   \n",
       "4             2               F         0                 0               1   \n",
       "\n",
       "   two_year_recid  \n",
       "0               0  \n",
       "1               1  \n",
       "2               1  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = my_df[['id', 'sex', 'age_cat', 'race', 'juv_fel_count',\n",
    "       'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "       'is_recid', 'is_violent_recid', 'decile_score.1',\n",
    "       'two_year_recid']]\n",
    "\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3696\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Other                377\n",
       "Asian                 32\n",
       "Native American       18\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3696\n",
       "Caucasian           2454\n",
       "Hispanic             637\n",
       "Other                427\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possible solution to overfitting, however will not use as it may lead to bias:\n",
    "void_df = my_df.copy()\n",
    "void_df[\"race\"] = void_df[\"race\"].replace({\"Native American\": \"Other\", \"Asian\": \"Other\"})\n",
    "void_df.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['sex','age_cat','race','c_charge_degree'] \n",
    "\n",
    "my_df = pd.get_dummies(my_df, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>sex_Female</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>...</th>\n",
       "      <th>age_cat_Greater than 45</th>\n",
       "      <th>age_cat_Less than 25</th>\n",
       "      <th>race_African-American</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>race_Native American</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  juv_fel_count  juv_misd_count  priors_count  is_recid  \\\n",
       "0   1              0               0             0         0   \n",
       "1   3              0               0             0         1   \n",
       "2   4              0               0             4         1   \n",
       "3   5              0               1             1         0   \n",
       "4   6              0               0             2         0   \n",
       "\n",
       "   is_violent_recid  decile_score.1  two_year_recid  sex_Female  sex_Male  \\\n",
       "0                 0               1               0           0         1   \n",
       "1                 1               3               1           0         1   \n",
       "2                 0               4               1           0         1   \n",
       "3                 0               8               0           0         1   \n",
       "4                 0               1               0           0         1   \n",
       "\n",
       "   ...  age_cat_Greater than 45  age_cat_Less than 25  race_African-American  \\\n",
       "0  ...                        1                     0                      0   \n",
       "1  ...                        0                     0                      1   \n",
       "2  ...                        0                     1                      1   \n",
       "3  ...                        0                     1                      1   \n",
       "4  ...                        0                     0                      0   \n",
       "\n",
       "   race_Asian  race_Caucasian  race_Hispanic  race_Native American  \\\n",
       "0           0               0              0                     0   \n",
       "1           0               0              0                     0   \n",
       "2           0               0              0                     0   \n",
       "3           0               0              0                     0   \n",
       "4           0               0              0                     0   \n",
       "\n",
       "   race_Other  c_charge_degree_F  c_charge_degree_M  \n",
       "0           1                  1                  0  \n",
       "1           0                  1                  0  \n",
       "2           0                  1                  0  \n",
       "3           0                  1                  0  \n",
       "4           1                  1                  0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "juv_fel_count              0\n",
       "juv_misd_count             0\n",
       "priors_count               0\n",
       "is_recid                   0\n",
       "is_violent_recid           0\n",
       "decile_score.1             0\n",
       "two_year_recid             0\n",
       "sex_Female                 0\n",
       "sex_Male                   0\n",
       "age_cat_25 - 45            0\n",
       "age_cat_Greater than 45    0\n",
       "age_cat_Less than 25       0\n",
       "race_African-American      0\n",
       "race_Asian                 0\n",
       "race_Caucasian             0\n",
       "race_Hispanic              0\n",
       "race_Native American       0\n",
       "race_Other                 0\n",
       "c_charge_degree_F          0\n",
       "c_charge_degree_M          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = my_df.drop(columns=[\"sex_Female\", \"race_Other\", \"c_charge_degree_M\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = my_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>age_cat_25 - 45</th>\n",
       "      <th>age_cat_Greater than 45</th>\n",
       "      <th>age_cat_Less than 25</th>\n",
       "      <th>race_African-American</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>race_Native American</th>\n",
       "      <th>c_charge_degree_F</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    juv_fel_count  juv_misd_count  priors_count  is_recid  is_violent_recid  \\\n",
       "id                                                                            \n",
       "1               0               0             0         0                 0   \n",
       "3               0               0             0         1                 1   \n",
       "4               0               0             4         1                 0   \n",
       "5               0               1             1         0                 0   \n",
       "6               0               0             2         0                 0   \n",
       "\n",
       "    decile_score.1  two_year_recid  sex_Male  age_cat_25 - 45  \\\n",
       "id                                                              \n",
       "1                1               0         1                0   \n",
       "3                3               1         1                1   \n",
       "4                4               1         1                0   \n",
       "5                8               0         1                0   \n",
       "6                1               0         1                1   \n",
       "\n",
       "    age_cat_Greater than 45  age_cat_Less than 25  race_African-American  \\\n",
       "id                                                                         \n",
       "1                         1                     0                      0   \n",
       "3                         0                     0                      1   \n",
       "4                         0                     1                      1   \n",
       "5                         0                     1                      1   \n",
       "6                         0                     0                      0   \n",
       "\n",
       "    race_Asian  race_Caucasian  race_Hispanic  race_Native American  \\\n",
       "id                                                                    \n",
       "1            0               0              0                     0   \n",
       "3            0               0              0                     0   \n",
       "4            0               0              0                     0   \n",
       "5            0               0              0                     0   \n",
       "6            0               0              0                     0   \n",
       "\n",
       "    c_charge_degree_F  \n",
       "id                     \n",
       "1                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "5                   1  \n",
       "6                   1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = my_df.drop(columns=[\"two_year_recid\"])\n",
    "y = my_df[\"two_year_recid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training testing and validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a df (\"X_value\") and prints a count of all features.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def feature_counter(X_value):\n",
    "    for feature in X_value.columns:\n",
    "        print(f\"{feature}: {Counter(X_value[feature])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3963, 1: 3251})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juv_fel_count: Counter({0: 6932, 1: 189, 2: 51, 3: 18, 4: 12, 5: 5, 8: 2, 6: 2, 9: 1, 20: 1, 10: 1})\n",
      "juv_misd_count: Counter({0: 6799, 1: 291, 2: 72, 3: 29, 4: 9, 5: 5, 6: 4, 8: 3, 12: 1, 13: 1})\n",
      "priors_count: Counter({0: 2150, 1: 1397, 2: 840, 3: 568, 4: 401, 5: 334, 6: 242, 7: 210, 8: 187, 9: 149, 10: 110, 11: 98, 13: 77, 12: 73, 14: 56, 15: 51, 16: 39, 17: 36, 19: 30, 18: 26, 20: 23, 21: 22, 22: 21, 23: 16, 24: 11, 25: 9, 28: 7, 27: 7, 26: 7, 29: 5, 33: 3, 30: 2, 38: 2, 31: 2, 36: 1, 37: 1, 35: 1})\n",
      "is_recid: Counter({0: 3743, 1: 3471})\n",
      "is_violent_recid: Counter({0: 6395, 1: 819})\n",
      "decile_score.1: Counter({1: 1440, 2: 941, 4: 769, 3: 747, 5: 681, 6: 641, 7: 592, 8: 512, 9: 508, 10: 383})\n",
      "sex_Male: Counter({1: 5819, 0: 1395})\n",
      "age_cat_25 - 45: Counter({1: 4109, 0: 3105})\n",
      "age_cat_Greater than 45: Counter({0: 5638, 1: 1576})\n",
      "age_cat_Less than 25: Counter({0: 5685, 1: 1529})\n",
      "race_African-American: Counter({1: 3696, 0: 3518})\n",
      "race_Asian: Counter({0: 7182, 1: 32})\n",
      "race_Caucasian: Counter({0: 4760, 1: 2454})\n",
      "race_Hispanic: Counter({0: 6577, 1: 637})\n",
      "race_Native American: Counter({0: 7196, 1: 18})\n",
      "c_charge_degree_F: Counter({1: 4666, 0: 2548})\n"
     ]
    }
   ],
   "source": [
    "feature_counter(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where I noticed the collinearity between is_recid and two_year_recid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting y and X values accordingly\n",
    "\n",
    "y = X[\"is_recid\"]\n",
    "X = X.drop(columns=[\"is_recid\", \"is_violent_recid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3743, 1: 3471})\n",
      "juv_fel_count: Counter({0: 6932, 1: 189, 2: 51, 3: 18, 4: 12, 5: 5, 8: 2, 6: 2, 9: 1, 20: 1, 10: 1})\n",
      "juv_misd_count: Counter({0: 6799, 1: 291, 2: 72, 3: 29, 4: 9, 5: 5, 6: 4, 8: 3, 12: 1, 13: 1})\n",
      "priors_count: Counter({0: 2150, 1: 1397, 2: 840, 3: 568, 4: 401, 5: 334, 6: 242, 7: 210, 8: 187, 9: 149, 10: 110, 11: 98, 13: 77, 12: 73, 14: 56, 15: 51, 16: 39, 17: 36, 19: 30, 18: 26, 20: 23, 21: 22, 22: 21, 23: 16, 24: 11, 25: 9, 28: 7, 27: 7, 26: 7, 29: 5, 33: 3, 30: 2, 38: 2, 31: 2, 36: 1, 37: 1, 35: 1})\n",
      "decile_score.1: Counter({1: 1440, 2: 941, 4: 769, 3: 747, 5: 681, 6: 641, 7: 592, 8: 512, 9: 508, 10: 383})\n",
      "sex_Male: Counter({1: 5819, 0: 1395})\n",
      "age_cat_25 - 45: Counter({1: 4109, 0: 3105})\n",
      "age_cat_Greater than 45: Counter({0: 5638, 1: 1576})\n",
      "age_cat_Less than 25: Counter({0: 5685, 1: 1529})\n",
      "race_African-American: Counter({1: 3696, 0: 3518})\n",
      "race_Asian: Counter({0: 7182, 1: 32})\n",
      "race_Caucasian: Counter({0: 4760, 1: 2454})\n",
      "race_Hispanic: Counter({0: 6577, 1: 637})\n",
      "race_Native American: Counter({0: 7196, 1: 18})\n",
      "c_charge_degree_F: Counter({1: 4666, 0: 2548})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y))\n",
    "feature_counter(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-split the data\n",
    "X = X.astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juv_fel_count: Counter({0: 1789, 1: 59, 2: 14, 3: 8, 4: 4, 5: 2, 9: 1, 10: 1, 20: 1})\n",
      "juv_misd_count: Counter({0: 1727, 1: 95, 2: 34, 3: 15, 5: 3, 4: 3, 8: 1, 12: 1})\n",
      "priors_count: Counter({0: 621, 1: 280, 2: 195, 3: 166, 4: 82, 7: 70, 8: 65, 6: 52, 5: 51, 11: 36, 10: 36, 9: 36, 13: 35, 12: 18, 17: 16, 16: 15, 19: 15, 14: 15, 18: 13, 23: 9, 22: 9, 15: 8, 21: 7, 25: 5, 28: 5, 20: 4, 24: 3, 26: 3, 29: 2, 30: 2, 27: 2, 36: 1, 37: 1, 31: 1})\n",
      "decile_score.1: Counter({1: 482, 2: 222, 8: 181, 10: 170, 9: 152, 5: 142, 6: 140, 3: 139, 7: 136, 4: 115})\n",
      "sex_Male: Counter({1: 1512, 0: 367})\n",
      "age_cat_25 - 45: Counter({1: 1071, 0: 808})\n",
      "age_cat_Greater than 45: Counter({0: 1443, 1: 436})\n",
      "age_cat_Less than 25: Counter({0: 1509, 1: 370})\n",
      "race_African-American: Counter({1: 950, 0: 929})\n",
      "race_Asian: Counter({0: 1865, 1: 14})\n",
      "race_Caucasian: Counter({0: 1256, 1: 623})\n",
      "race_Hispanic: Counter({0: 1714, 1: 165})\n",
      "race_Native American: Counter({0: 1871, 1: 8})\n",
      "c_charge_degree_F: Counter({1: 1286, 0: 593})\n"
     ]
    }
   ],
   "source": [
    "# resample data with SMOTEENN\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "sme = SMOTEENN(random_state=42)\n",
    "\n",
    "X_sme, y_sme = sme.fit_resample(X_train, y_train)\n",
    "\n",
    "feature_counter(X_sme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the data \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_sme_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Logistic Regression with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 336 candidates, totalling 3360 fits\n",
      "Best parameters found:  {'C': 0.01, 'class_weight': 'balanced', 'max_iter': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best cross-validation score: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\cainhurst\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "840 fits failed out of a total of 3360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "840 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\cainhurst\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\cainhurst\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\cainhurst\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramData\\anaconda3\\envs\\cainhurst\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.64893075        nan 0.67110787 0.66694992 0.51186965        nan\n",
      " 0.67197502 0.67232164 0.51186965        nan 0.67232164 0.67232164\n",
      " 0.51186965        nan 0.67232164 0.67232164 0.51186965        nan\n",
      " 0.67232164 0.67232164 0.51186965        nan 0.67232164 0.67232164\n",
      " 0.51186965        nan 0.67232164 0.67232164 0.64979701        nan\n",
      " 0.67232224 0.66417726 0.50944751        nan 0.67266976 0.67284337\n",
      " 0.51186965        nan 0.67267006 0.67267006 0.51186965        nan\n",
      " 0.67267006 0.67267006 0.51186965        nan 0.67267006 0.67267006\n",
      " 0.51186965        nan 0.67267006 0.67267006 0.51186965        nan\n",
      " 0.67267006 0.67267006 0.67353571        nan 0.67388083 0.66694992\n",
      " 0.67180411        nan 0.67318879 0.67249615 0.67180411        nan\n",
      " 0.67284277 0.67266946 0.67180411        nan 0.67301608 0.67301608\n",
      " 0.67180411        nan 0.67301608 0.67301608 0.67180411        nan\n",
      " 0.67301608 0.67301608 0.67180411        nan 0.67301608 0.67301608\n",
      " 0.67318819        nan 0.67561513 0.66417726 0.67405594        nan\n",
      " 0.67284337 0.67249675 0.67423015        nan 0.67318999 0.67301668\n",
      " 0.67405684        nan 0.6733633  0.6733633  0.67405684        nan\n",
      " 0.6733633  0.6733633  0.67405684        nan 0.6733633  0.6733633\n",
      " 0.67405684        nan 0.6733633  0.6733633  0.67318819        nan\n",
      " 0.67301458 0.66694992 0.6733624         nan 0.67266916 0.67353451\n",
      " 0.67266946        nan 0.67197712 0.67145719 0.67249615        nan\n",
      " 0.67128387 0.67128387 0.67249615        nan 0.67128387 0.67128387\n",
      " 0.67249615        nan 0.67128387 0.67128387 0.67249615        nan\n",
      " 0.67128387 0.67128387 0.67405564        nan 0.67492249 0.66417726\n",
      " 0.67371022        nan 0.67180351 0.67215013 0.67301728        nan\n",
      " 0.67232344 0.67215013 0.67301728        nan 0.67232344 0.67232344\n",
      " 0.67301728        nan 0.67232344 0.67232344 0.67301728        nan\n",
      " 0.67232344 0.67232344 0.67301728        nan 0.67232344 0.67232344\n",
      " 0.6733612         nan 0.6733612  0.66694992 0.67266976        nan\n",
      " 0.67266976 0.6733612  0.67214983        nan 0.67215013 0.67145719\n",
      " 0.67197682        nan 0.6716305  0.6716305  0.67197682        nan\n",
      " 0.6716305  0.6716305  0.67197682        nan 0.6716305  0.6716305\n",
      " 0.67197682        nan 0.6716305  0.6716305  0.67457557        nan\n",
      " 0.67492219 0.66417726 0.67197682        nan 0.6716302  0.67197682\n",
      " 0.67180351        nan 0.67197682 0.67249675 0.67232344        nan\n",
      " 0.67197682 0.67197682 0.67232344        nan 0.67197682 0.67197682\n",
      " 0.67232344        nan 0.67197682 0.67197682 0.67232344        nan\n",
      " 0.67197682 0.67197682 0.6733612         nan 0.6733612  0.66694992\n",
      " 0.67266976        nan 0.67266976 0.67318789 0.67215013        nan\n",
      " 0.67215013 0.67145719 0.67145719        nan 0.6716305  0.6716305\n",
      " 0.67145719        nan 0.6716305  0.6716305  0.67145719        nan\n",
      " 0.6716305  0.6716305  0.67145719        nan 0.6716305  0.6716305\n",
      " 0.67492219        nan 0.67492219 0.66417726 0.6716302         nan\n",
      " 0.6716302  0.67197682 0.67215013        nan 0.67215013 0.67249675\n",
      " 0.67215013        nan 0.67215013 0.67215013 0.67215013        nan\n",
      " 0.67215013 0.67215013 0.67215013        nan 0.67215013 0.67215013\n",
      " 0.67215013        nan 0.67215013 0.67215013 0.6733612         nan\n",
      " 0.67353451 0.66694992 0.67266976        nan 0.67266976 0.67301458\n",
      " 0.67215013        nan 0.67215013 0.67145719 0.6716305         nan\n",
      " 0.6716305  0.67145719 0.6716305         nan 0.6716305  0.67145719\n",
      " 0.6716305         nan 0.6716305  0.67145719 0.6716305         nan\n",
      " 0.6716305  0.67145719 0.67492219        nan 0.67492219 0.66417726\n",
      " 0.6716302         nan 0.6716302  0.67197682 0.67215013        nan\n",
      " 0.67215013 0.67249675 0.67215013        nan 0.67215013 0.67215013\n",
      " 0.67215013        nan 0.67215013 0.67215013 0.67215013        nan\n",
      " 0.67215013 0.67215013 0.67215013        nan 0.67215013 0.67215013]\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\cainhurst\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['saga', 'lbfgs'], \n",
    "    'max_iter': [1, 5, 10, 50, 100, 500, 1000],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=10), param_grid, cv=10, verbose=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_sme_scaled, y_train)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Balanced Accuracy Score: 0.6649864536458878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Define the best_model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Now, you can use best_model to make predictions\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "test_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Balanced Accuracy Score: {test_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[533, 256],\n",
       "       [226, 428]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       789\n",
      "           1       0.63      0.65      0.64       654\n",
      "\n",
      "    accuracy                           0.67      1443\n",
      "   macro avg       0.66      0.66      0.66      1443\n",
      "weighted avg       0.67      0.67      0.67      1443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Assuming 'model' is your trained logistic regression model and 'feature_names' is a list of feature names\n",
    "coefficients = best_model.coef_[0]\n",
    "feature_names = X_train.columns  # or the list of your feature names\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "sorted_idx = np.argsort(np.abs(coefficients))[::-1]\n",
    "plt.barh(np.array(feature_names)[sorted_idx], coefficients[sorted_idx])\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.title(\"Logistic Regression Feature Importance\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 10, 'max_features': 'log2', 'max_depth': 8, 'class_weight': 'balanced_subsample'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_dist = {'n_estimators': [10, 20, 40, 80, 100, 200],\n",
    "              'max_depth': [2, 4, 8, 16, 32],\n",
    "              \"max_features\": ['sqrt', 'log2', None],\n",
    "              \"class_weight\": ['balanced', 'balanced_subsample', None]\n",
    "              }\n",
    "\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist,\n",
    "                                 n_jobs=-1, \n",
    "                                 verbose=3,\n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "\n",
    "rand_search.fit(X_sme_scaled, y_train)\n",
    "\n",
    "# Create a variable for the best model\n",
    "best_rf = rand_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print('Best hyperparameters:',  rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy Score: 0.6734456576086325\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the balanced accuracy score\n",
    "score = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Balanced Accuracy Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[556, 233],\n",
       "       [234, 420]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       789\n",
      "           1       0.64      0.64      0.64       654\n",
      "\n",
      "    accuracy                           0.68      1443\n",
      "   macro avg       0.67      0.67      0.67      1443\n",
      "weighted avg       0.68      0.68      0.68      1443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "271/271 [==============================] - 5s 4ms/step - loss: 0.6808 - accuracy: 0.5538 - val_loss: 0.6552 - val_accuracy: 0.6577\n",
      "Epoch 2/10\n",
      "271/271 [==============================] - 1s 3ms/step - loss: 0.6622 - accuracy: 0.6377 - val_loss: 0.6408 - val_accuracy: 0.6681\n",
      "Epoch 3/10\n",
      "271/271 [==============================] - 1s 3ms/step - loss: 0.6481 - accuracy: 0.6534 - val_loss: 0.6328 - val_accuracy: 0.6729\n",
      "Epoch 4/10\n",
      "271/271 [==============================] - 1s 3ms/step - loss: 0.6455 - accuracy: 0.6520 - val_loss: 0.6290 - val_accuracy: 0.6722\n",
      "Epoch 5/10\n",
      "271/271 [==============================] - 1s 3ms/step - loss: 0.6425 - accuracy: 0.6527 - val_loss: 0.6289 - val_accuracy: 0.6701\n",
      "Epoch 6/10\n",
      "271/271 [==============================] - 1s 3ms/step - loss: 0.6337 - accuracy: 0.6650 - val_loss: 0.6274 - val_accuracy: 0.6660\n",
      "Epoch 7/10\n",
      "271/271 [==============================] - 1s 3ms/step - loss: 0.6394 - accuracy: 0.6592 - val_loss: 0.6214 - val_accuracy: 0.6681\n",
      "Epoch 8/10\n",
      "271/271 [==============================] - 1s 3ms/step - loss: 0.6290 - accuracy: 0.6647 - val_loss: 0.6219 - val_accuracy: 0.6743\n",
      "Epoch 9/10\n",
      "271/271 [==============================] - 1s 4ms/step - loss: 0.6331 - accuracy: 0.6624 - val_loss: 0.6223 - val_accuracy: 0.6805\n",
      "Epoch 10/10\n",
      "271/271 [==============================] - 1s 4ms/step - loss: 0.6269 - accuracy: 0.6636 - val_loss: 0.6193 - val_accuracy: 0.6764\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.6805\n",
      "Test Accuracy: 0.6805266737937927\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_sme_scaled.shape[1],)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "model.fit(X_sme_scaled, y_train, epochs=10, batch_size=16, validation_split=0.25)\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2700 candidates, totalling 13500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.001, 0.01, 0.05, 0.1, 10],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10, 20],\n",
       "                         &#x27;min_child_weight&#x27;: [1, 3, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.7, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;learning_rate&#x27;: [0.001, 0.01, 0.05, 0.1, 10],\n",
       "                         &#x27;max_depth&#x27;: [3, 5, 7, 10, 20],\n",
       "                         &#x27;min_child_weight&#x27;: [1, 3, 5],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200, 300],\n",
       "                         &#x27;subsample&#x27;: [0.5, 0.7, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='logloss', feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7, 1.0],\n",
       "                         'learning_rate': [0.001, 0.01, 0.05, 0.1, 10],\n",
       "                         'max_depth': [3, 5, 7, 10, 20],\n",
       "                         'min_child_weight': [1, 3, 5],\n",
       "                         'n_estimators': [50, 100, 200, 300],\n",
       "                         'subsample': [0.5, 0.7, 1.0]},\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1, 10],\n",
    "    'max_depth': [3, 5, 7, 10, 20],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0],\n",
    "    'n_estimators': [50, 100, 200, 300]\n",
    "}\n",
    "\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', verbose=10, n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 0.7}\n",
      "Best cross-validation score: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       789\n",
      "           1       0.64      0.66      0.65       654\n",
      "\n",
      "    accuracy                           0.68      1443\n",
      "   macro avg       0.68      0.68      0.68      1443\n",
      "weighted avg       0.68      0.68      0.68      1443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_xgb.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .C=0.01, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   9.9s\n",
      "[CV] END .C=0.01, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   3.9s\n",
      "[CV] END .C=0.01, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   3.4s\n",
      "[CV] END .C=0.01, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   3.5s\n",
      "[CV] END .C=0.01, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   3.8s\n",
      "[CV] END .C=1, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   2.4s\n",
      "[CV] END .C=1, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   2.5s\n",
      "[CV] END .C=1, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   4.3s\n",
      "[CV] END .C=1, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   2.5s\n",
      "[CV] END .C=1, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   2.7s\n",
      "[CV] END ...C=0.1, coef0=1, degree=4, gamma=auto, kernel=rbf; total time=   3.0s\n",
      "[CV] END ...C=0.1, coef0=1, degree=4, gamma=auto, kernel=rbf; total time=   3.8s\n",
      "[CV] END ...C=0.1, coef0=1, degree=4, gamma=auto, kernel=rbf; total time=   2.8s\n",
      "[CV] END ...C=0.1, coef0=1, degree=4, gamma=auto, kernel=rbf; total time=   3.0s\n",
      "[CV] END ...C=0.1, coef0=1, degree=4, gamma=auto, kernel=rbf; total time=   3.1s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   1.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   1.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   2.2s\n",
      "[CV] END ....C=1, coef0=-1, degree=4, gamma=0.01, kernel=rbf; total time=   4.4s\n",
      "[CV] END ....C=1, coef0=-1, degree=4, gamma=0.01, kernel=rbf; total time=   2.9s\n",
      "[CV] END ....C=1, coef0=-1, degree=4, gamma=0.01, kernel=rbf; total time=   3.1s\n",
      "[CV] END ....C=1, coef0=-1, degree=4, gamma=0.01, kernel=rbf; total time=   2.8s\n",
      "[CV] END ....C=1, coef0=-1, degree=4, gamma=0.01, kernel=rbf; total time=   3.4s\n",
      "[CV] END ....C=10, coef0=0, degree=2, gamma=0.01, kernel=rbf; total time=   4.9s\n",
      "[CV] END ....C=10, coef0=0, degree=2, gamma=0.01, kernel=rbf; total time=   3.3s\n",
      "[CV] END ....C=10, coef0=0, degree=2, gamma=0.01, kernel=rbf; total time=   3.8s\n",
      "[CV] END ....C=10, coef0=0, degree=2, gamma=0.01, kernel=rbf; total time=   4.1s\n",
      "[CV] END ....C=10, coef0=0, degree=2, gamma=0.01, kernel=rbf; total time=   3.1s\n",
      "[CV] END ..C=100, coef0=1, degree=3, gamma=auto, kernel=poly; total time=  43.8s\n",
      "[CV] END ..C=100, coef0=1, degree=3, gamma=auto, kernel=poly; total time= 1.2min\n",
      "[CV] END ..C=100, coef0=1, degree=3, gamma=auto, kernel=poly; total time=  50.8s\n",
      "[CV] END ..C=100, coef0=1, degree=3, gamma=auto, kernel=poly; total time= 1.1min\n",
      "[CV] END ..C=100, coef0=1, degree=3, gamma=auto, kernel=poly; total time=  30.9s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   3.3s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   3.7s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   3.2s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   3.1s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   3.3s\n",
      "[CV] END C=100, coef0=-1, degree=3, gamma=auto, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=100, coef0=-1, degree=3, gamma=auto, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END C=100, coef0=-1, degree=3, gamma=auto, kernel=sigmoid; total time=   3.4s\n",
      "[CV] END C=100, coef0=-1, degree=3, gamma=auto, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=100, coef0=-1, degree=3, gamma=auto, kernel=sigmoid; total time=   2.2s\n",
      "[CV] END ..C=0.01, coef0=1, degree=4, gamma=0.01, kernel=rbf; total time=   2.5s\n",
      "[CV] END ..C=0.01, coef0=1, degree=4, gamma=0.01, kernel=rbf; total time=   2.3s\n",
      "[CV] END ..C=0.01, coef0=1, degree=4, gamma=0.01, kernel=rbf; total time=   3.7s\n",
      "[CV] END ..C=0.01, coef0=1, degree=4, gamma=0.01, kernel=rbf; total time=   3.4s\n",
      "[CV] END ..C=0.01, coef0=1, degree=4, gamma=0.01, kernel=rbf; total time=   3.4s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=1, kernel=linear; total time=   2.9s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=1, kernel=linear; total time=   3.1s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=1, kernel=linear; total time=   2.6s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=1, kernel=linear; total time=   2.5s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=1, kernel=linear; total time=   2.7s\n",
      "[CV] END C=0.01, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   2.7s\n",
      "[CV] END C=0.01, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   2.9s\n",
      "[CV] END C=0.01, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   2.7s\n",
      "[CV] END C=0.01, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END C=0.01, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   2.0s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=auto, kernel=sigmoid; total time=   2.5s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=auto, kernel=sigmoid; total time=   2.5s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=auto, kernel=sigmoid; total time=   3.2s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=auto, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=auto, kernel=sigmoid; total time=   2.5s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   2.2s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   2.9s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   2.5s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   2.3s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   2.3s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=auto, kernel=linear; total time=   1.4s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=auto, kernel=linear; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=auto, kernel=linear; total time=   2.5s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=auto, kernel=linear; total time=   3.1s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=auto, kernel=linear; total time=   2.3s\n",
      "[CV] END .C=100, coef0=0, degree=4, gamma=0.1, kernel=linear; total time=  18.5s\n",
      "[CV] END .C=100, coef0=0, degree=4, gamma=0.1, kernel=linear; total time=  20.6s\n",
      "[CV] END .C=100, coef0=0, degree=4, gamma=0.1, kernel=linear; total time=  14.7s\n",
      "[CV] END .C=100, coef0=0, degree=4, gamma=0.1, kernel=linear; total time=  47.7s\n",
      "[CV] END .C=100, coef0=0, degree=4, gamma=0.1, kernel=linear; total time=  23.9s\n",
      "[CV] END .C=1, coef0=0, degree=2, gamma=auto, kernel=sigmoid; total time=   4.1s\n",
      "[CV] END .C=1, coef0=0, degree=2, gamma=auto, kernel=sigmoid; total time=   2.3s\n",
      "[CV] END .C=1, coef0=0, degree=2, gamma=auto, kernel=sigmoid; total time=   2.4s\n",
      "[CV] END .C=1, coef0=0, degree=2, gamma=auto, kernel=sigmoid; total time=   2.4s\n",
      "[CV] END .C=1, coef0=0, degree=2, gamma=auto, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END ........C=1, coef0=0, degree=5, gamma=1, kernel=rbf; total time=   4.1s\n",
      "[CV] END ........C=1, coef0=0, degree=5, gamma=1, kernel=rbf; total time=   4.2s\n",
      "[CV] END ........C=1, coef0=0, degree=5, gamma=1, kernel=rbf; total time=   4.2s\n",
      "[CV] END ........C=1, coef0=0, degree=5, gamma=1, kernel=rbf; total time=   4.1s\n",
      "[CV] END ........C=1, coef0=0, degree=5, gamma=1, kernel=rbf; total time=   3.1s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=scale, kernel=poly; total time=   0.8s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=scale, kernel=poly; total time=   0.8s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=scale, kernel=poly; total time=   0.8s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=scale, kernel=poly; total time=   1.1s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=scale, kernel=poly; total time=   1.5s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=4, gamma=1, kernel=poly; total time=   2.3s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=4, gamma=1, kernel=poly; total time=   2.0s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=4, gamma=1, kernel=poly; total time=   2.2s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=4, gamma=1, kernel=poly; total time=   1.9s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=4, gamma=1, kernel=poly; total time=   2.1s\n",
      "[CV] END .C=100, coef0=-1, degree=3, gamma=scale, kernel=rbf; total time=   4.1s\n",
      "[CV] END .C=100, coef0=-1, degree=3, gamma=scale, kernel=rbf; total time=   4.0s\n",
      "[CV] END .C=100, coef0=-1, degree=3, gamma=scale, kernel=rbf; total time=   4.2s\n",
      "[CV] END .C=100, coef0=-1, degree=3, gamma=scale, kernel=rbf; total time=   4.5s\n",
      "[CV] END .C=100, coef0=-1, degree=3, gamma=scale, kernel=rbf; total time=   4.1s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=1, kernel=sigmoid; total time=   2.9s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=1, kernel=sigmoid; total time=   3.2s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=1, kernel=sigmoid; total time=   4.3s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=1, kernel=sigmoid; total time=   3.3s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=1, kernel=sigmoid; total time=   3.1s\n",
      "[CV] END .......C=10, coef0=1, degree=5, gamma=1, kernel=rbf; total time=   3.2s\n",
      "[CV] END .......C=10, coef0=1, degree=5, gamma=1, kernel=rbf; total time=   3.4s\n",
      "[CV] END .......C=10, coef0=1, degree=5, gamma=1, kernel=rbf; total time=   3.7s\n",
      "[CV] END .......C=10, coef0=1, degree=5, gamma=1, kernel=rbf; total time=   4.7s\n",
      "[CV] END .......C=10, coef0=1, degree=5, gamma=1, kernel=rbf; total time=   4.3s\n",
      "[CV] END ....C=1, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   2.9s\n",
      "[CV] END ....C=1, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   3.8s\n",
      "[CV] END ....C=1, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   4.0s\n",
      "[CV] END ....C=1, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   5.8s\n",
      "[CV] END ....C=1, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   5.8s\n",
      "[CV] END C=1, coef0=1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.9s\n",
      "[CV] END C=1, coef0=1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.8s\n",
      "[CV] END C=1, coef0=1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.0s\n",
      "[CV] END C=1, coef0=1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.9s\n",
      "[CV] END C=1, coef0=1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.9s\n",
      "[CV] END ...C=1, coef0=0, degree=5, gamma=0.001, kernel=poly; total time=   4.9s\n",
      "[CV] END ...C=1, coef0=0, degree=5, gamma=0.001, kernel=poly; total time=   2.5s\n",
      "[CV] END ...C=1, coef0=0, degree=5, gamma=0.001, kernel=poly; total time=   2.7s\n",
      "[CV] END ...C=1, coef0=0, degree=5, gamma=0.001, kernel=poly; total time=   2.3s\n",
      "[CV] END ...C=1, coef0=0, degree=5, gamma=0.001, kernel=poly; total time=   2.5s\n",
      "[CV] END ...C=1, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   1.9s\n",
      "[CV] END ...C=1, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   6.6s\n",
      "[CV] END ...C=1, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   6.2s\n",
      "[CV] END ...C=1, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   5.3s\n",
      "[CV] END ...C=1, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   3.6s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=sigmoid; total time=   4.6s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=sigmoid; total time=   3.3s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=sigmoid; total time=   3.3s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=sigmoid; total time=   3.2s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=sigmoid; total time=   3.7s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.4s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.9s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.5s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=sigmoid; total time=   4.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=sigmoid; total time=   6.4s\n",
      "[CV] END .C=0.01, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   2.7s\n",
      "[CV] END .C=0.01, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   2.7s\n",
      "[CV] END .C=0.01, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   2.6s\n",
      "[CV] END .C=0.01, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   3.1s\n",
      "[CV] END .C=0.01, coef0=1, degree=5, gamma=0.01, kernel=poly; total time=   3.3s\n",
      "[CV] END ..C=10, coef0=-1, degree=3, gamma=0.01, kernel=poly; total time=   3.6s\n",
      "[CV] END ..C=10, coef0=-1, degree=3, gamma=0.01, kernel=poly; total time=   1.5s\n",
      "[CV] END ..C=10, coef0=-1, degree=3, gamma=0.01, kernel=poly; total time=   1.3s\n",
      "[CV] END ..C=10, coef0=-1, degree=3, gamma=0.01, kernel=poly; total time=   1.5s\n",
      "[CV] END ..C=10, coef0=-1, degree=3, gamma=0.01, kernel=poly; total time=   1.4s\n",
      "[CV] END ..C=10, coef0=1, degree=4, gamma=0.1, kernel=linear; total time=   3.5s\n",
      "[CV] END ..C=10, coef0=1, degree=4, gamma=0.1, kernel=linear; total time=   2.6s\n",
      "[CV] END ..C=10, coef0=1, degree=4, gamma=0.1, kernel=linear; total time=   3.2s\n",
      "[CV] END ..C=10, coef0=1, degree=4, gamma=0.1, kernel=linear; total time=   3.2s\n",
      "[CV] END ..C=10, coef0=1, degree=4, gamma=0.1, kernel=linear; total time=   3.1s\n",
      "[CV] END C=10, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   1.3s\n",
      "[CV] END C=10, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   0.9s\n",
      "[CV] END C=10, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   1.2s\n",
      "[CV] END C=10, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END C=10, coef0=0, degree=2, gamma=scale, kernel=sigmoid; total time=   0.8s\n",
      "[CV] END .......C=1, coef0=-1, degree=4, gamma=1, kernel=rbf; total time=   1.5s\n",
      "[CV] END .......C=1, coef0=-1, degree=4, gamma=1, kernel=rbf; total time=   1.5s\n",
      "[CV] END .......C=1, coef0=-1, degree=4, gamma=1, kernel=rbf; total time=   2.2s\n",
      "[CV] END .......C=1, coef0=-1, degree=4, gamma=1, kernel=rbf; total time=   2.1s\n",
      "[CV] END .......C=1, coef0=-1, degree=4, gamma=1, kernel=rbf; total time=   2.0s\n",
      "[CV] END C=0.1, coef0=1, degree=4, gamma=0.01, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END C=0.1, coef0=1, degree=4, gamma=0.01, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END C=0.1, coef0=1, degree=4, gamma=0.01, kernel=sigmoid; total time=   1.5s\n",
      "[CV] END C=0.1, coef0=1, degree=4, gamma=0.01, kernel=sigmoid; total time=   3.1s\n",
      "[CV] END C=0.1, coef0=1, degree=4, gamma=0.01, kernel=sigmoid; total time=   2.9s\n",
      "[CV] END .C=1, coef0=1, degree=5, gamma=0.01, kernel=sigmoid; total time=   2.2s\n",
      "[CV] END .C=1, coef0=1, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.5s\n",
      "[CV] END .C=1, coef0=1, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END .C=1, coef0=1, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END .C=1, coef0=1, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.3s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=0.001, kernel=linear; total time=   0.6s\n",
      "[CV] END ..C=0.01, coef0=1, degree=5, gamma=0.1, kernel=poly; total time=   1.0s\n",
      "[CV] END ..C=0.01, coef0=1, degree=5, gamma=0.1, kernel=poly; total time=   0.9s\n",
      "[CV] END ..C=0.01, coef0=1, degree=5, gamma=0.1, kernel=poly; total time=   0.9s\n",
      "[CV] END ..C=0.01, coef0=1, degree=5, gamma=0.1, kernel=poly; total time=   1.1s\n",
      "[CV] END ..C=0.01, coef0=1, degree=5, gamma=0.1, kernel=poly; total time=   1.1s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=0.01, kernel=sigmoid; total time=   1.5s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=0.01, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=0.01, kernel=sigmoid; total time=   1.7s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=0.01, kernel=sigmoid; total time=   1.7s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=0.01, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=0.01, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   0.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   0.7s\n",
      "[CV] END C=0.01, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   0.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   0.7s\n",
      "[CV] END C=0.01, coef0=-1, degree=3, gamma=0.01, kernel=linear; total time=   0.7s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=auto, kernel=poly; total time=   0.3s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=auto, kernel=poly; total time=   0.4s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=auto, kernel=poly; total time=   0.6s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=auto, kernel=poly; total time=   0.5s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=auto, kernel=poly; total time=   0.5s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=0.001, kernel=rbf; total time=   1.5s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=0.001, kernel=rbf; total time=   1.3s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=0.001, kernel=rbf; total time=   1.3s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=0.001, kernel=rbf; total time=   1.3s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=auto, kernel=poly; total time=   0.9s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=auto, kernel=poly; total time=   1.1s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=auto, kernel=poly; total time=   3.1s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=auto, kernel=poly; total time=   2.3s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=auto, kernel=poly; total time=   1.6s\n",
      "[CV] END C=0.01, coef0=1, degree=5, gamma=0.1, kernel=sigmoid; total time=   2.4s\n",
      "[CV] END C=0.01, coef0=1, degree=5, gamma=0.1, kernel=sigmoid; total time=   1.9s\n",
      "[CV] END C=0.01, coef0=1, degree=5, gamma=0.1, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=0.01, coef0=1, degree=5, gamma=0.1, kernel=sigmoid; total time=   2.2s\n",
      "[CV] END C=0.01, coef0=1, degree=5, gamma=0.1, kernel=sigmoid; total time=   2.2s\n",
      "[CV] END .....C=1, coef0=1, degree=2, gamma=0.01, kernel=rbf; total time=   1.4s\n",
      "[CV] END .....C=1, coef0=1, degree=2, gamma=0.01, kernel=rbf; total time=   3.3s\n",
      "[CV] END .....C=1, coef0=1, degree=2, gamma=0.01, kernel=rbf; total time=   3.9s\n",
      "[CV] END .....C=1, coef0=1, degree=2, gamma=0.01, kernel=rbf; total time=   3.3s\n",
      "[CV] END .....C=1, coef0=1, degree=2, gamma=0.01, kernel=rbf; total time=   1.7s\n",
      "[CV] END .C=100, coef0=0, degree=5, gamma=0.1, kernel=linear; total time=  14.5s\n",
      "[CV] END .C=100, coef0=0, degree=5, gamma=0.1, kernel=linear; total time=  13.2s\n",
      "[CV] END .C=100, coef0=0, degree=5, gamma=0.1, kernel=linear; total time=  10.6s\n",
      "[CV] END .C=100, coef0=0, degree=5, gamma=0.1, kernel=linear; total time=  28.4s\n",
      "[CV] END .C=100, coef0=0, degree=5, gamma=0.1, kernel=linear; total time=  10.9s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=scale, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END .C=0.01, coef0=1, degree=4, gamma=0.001, kernel=rbf; total time=   1.7s\n",
      "[CV] END .C=0.01, coef0=1, degree=4, gamma=0.001, kernel=rbf; total time=   2.2s\n",
      "[CV] END .C=0.01, coef0=1, degree=4, gamma=0.001, kernel=rbf; total time=   3.2s\n",
      "[CV] END .C=0.01, coef0=1, degree=4, gamma=0.001, kernel=rbf; total time=   1.8s\n",
      "[CV] END .C=0.01, coef0=1, degree=4, gamma=0.001, kernel=rbf; total time=   1.8s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.001, kernel=rbf; total time=   1.5s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.001, kernel=rbf; total time=   1.4s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.001, kernel=rbf; total time=   1.4s\n",
      "[CV] END ..C=100, coef0=1, degree=5, gamma=0.001, kernel=rbf; total time=   1.5s\n",
      "[CV] END .....C=0.1, coef0=-1, degree=3, gamma=1, kernel=rbf; total time=   1.5s\n",
      "[CV] END .....C=0.1, coef0=-1, degree=3, gamma=1, kernel=rbf; total time=   1.9s\n",
      "[CV] END .....C=0.1, coef0=-1, degree=3, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END .....C=0.1, coef0=-1, degree=3, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END .....C=0.1, coef0=-1, degree=3, gamma=1, kernel=rbf; total time=   1.8s\n",
      "[CV] END C=10, coef0=1, degree=4, gamma=0.001, kernel=linear; total time=   2.2s\n",
      "[CV] END C=10, coef0=1, degree=4, gamma=0.001, kernel=linear; total time=   2.0s\n",
      "[CV] END C=10, coef0=1, degree=4, gamma=0.001, kernel=linear; total time=   2.3s\n",
      "[CV] END C=10, coef0=1, degree=4, gamma=0.001, kernel=linear; total time=   2.1s\n",
      "[CV] END C=10, coef0=1, degree=4, gamma=0.001, kernel=linear; total time=   2.5s\n",
      "[CV] END .C=1, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=   1.3s\n",
      "[CV] END .C=1, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=   1.4s\n",
      "[CV] END .C=1, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=   1.6s\n",
      "[CV] END .C=1, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=   1.7s\n",
      "[CV] END .C=1, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END ....C=100, coef0=1, degree=3, gamma=0.1, kernel=rbf; total time=   2.7s\n",
      "[CV] END ....C=100, coef0=1, degree=3, gamma=0.1, kernel=rbf; total time=   3.0s\n",
      "[CV] END ....C=100, coef0=1, degree=3, gamma=0.1, kernel=rbf; total time=   2.3s\n",
      "[CV] END ....C=100, coef0=1, degree=3, gamma=0.1, kernel=rbf; total time=   2.4s\n",
      "[CV] END ....C=100, coef0=1, degree=3, gamma=0.1, kernel=rbf; total time=   2.5s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=   9.7s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=  12.4s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=  10.3s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=  21.8s\n",
      "[CV] END C=100, coef0=-1, degree=2, gamma=auto, kernel=linear; total time=   9.2s\n",
      "[CV] END .......C=1, coef0=-1, degree=5, gamma=1, kernel=rbf; total time=   1.5s\n",
      "[CV] END .......C=1, coef0=-1, degree=5, gamma=1, kernel=rbf; total time=   1.8s\n",
      "[CV] END .......C=1, coef0=-1, degree=5, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END .......C=1, coef0=-1, degree=5, gamma=1, kernel=rbf; total time=   1.8s\n",
      "[CV] END .......C=1, coef0=-1, degree=5, gamma=1, kernel=rbf; total time=   1.7s\n",
      "[CV] END C=10, coef0=-1, degree=3, gamma=auto, kernel=linear; total time=   2.0s\n",
      "[CV] END C=10, coef0=-1, degree=3, gamma=auto, kernel=linear; total time=   1.9s\n",
      "[CV] END C=10, coef0=-1, degree=3, gamma=auto, kernel=linear; total time=   2.1s\n",
      "[CV] END C=10, coef0=-1, degree=3, gamma=auto, kernel=linear; total time=   1.8s\n",
      "[CV] END C=10, coef0=-1, degree=3, gamma=auto, kernel=linear; total time=   2.0s\n",
      "[CV] END ...C=0.1, coef0=0, degree=3, gamma=auto, kernel=rbf; total time=   1.4s\n",
      "[CV] END ...C=0.1, coef0=0, degree=3, gamma=auto, kernel=rbf; total time=   1.3s\n",
      "[CV] END ...C=0.1, coef0=0, degree=3, gamma=auto, kernel=rbf; total time=   1.2s\n",
      "[CV] END ...C=0.1, coef0=0, degree=3, gamma=auto, kernel=rbf; total time=   1.3s\n",
      "[CV] END ...C=0.1, coef0=0, degree=3, gamma=auto, kernel=rbf; total time=   1.2s\n",
      "[CV] END C=10, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   0.9s\n",
      "[CV] END C=10, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END C=10, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END C=10, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END C=10, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END ......C=10, coef0=0, degree=2, gamma=1, kernel=poly; total time= 1.3min\n",
      "[CV] END ......C=10, coef0=0, degree=2, gamma=1, kernel=poly; total time= 2.1min\n",
      "[CV] END ......C=10, coef0=0, degree=2, gamma=1, kernel=poly; total time= 1.5min\n",
      "[CV] END ......C=10, coef0=0, degree=2, gamma=1, kernel=poly; total time= 2.1min\n",
      "[CV] END ......C=10, coef0=0, degree=2, gamma=1, kernel=poly; total time= 1.7min\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END C=0.01, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END ..C=0.1, coef0=1, degree=4, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END ..C=0.1, coef0=1, degree=4, gamma=0.01, kernel=poly; total time=   0.8s\n",
      "[CV] END ..C=0.1, coef0=1, degree=4, gamma=0.01, kernel=poly; total time=   0.9s\n",
      "[CV] END ..C=0.1, coef0=1, degree=4, gamma=0.01, kernel=poly; total time=   0.8s\n",
      "[CV] END ..C=0.1, coef0=1, degree=4, gamma=0.01, kernel=poly; total time=   0.9s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.001, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.001, kernel=sigmoid; total time=   1.2s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.001, kernel=sigmoid; total time=   1.2s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.001, kernel=sigmoid; total time=   1.2s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.001, kernel=sigmoid; total time=   1.7s\n",
      "[CV] END C=100, coef0=1, degree=3, gamma=0.1, kernel=sigmoid; total time=   1.5s\n",
      "[CV] END C=100, coef0=1, degree=3, gamma=0.1, kernel=sigmoid; total time=   1.3s\n",
      "[CV] END C=100, coef0=1, degree=3, gamma=0.1, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END C=100, coef0=1, degree=3, gamma=0.1, kernel=sigmoid; total time=   1.2s\n",
      "[CV] END C=100, coef0=1, degree=3, gamma=0.1, kernel=sigmoid; total time=   1.6s\n",
      "[CV] END C=0.01, coef0=1, degree=3, gamma=auto, kernel=linear; total time=   0.8s\n",
      "[CV] END C=0.01, coef0=1, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.01, coef0=1, degree=3, gamma=auto, kernel=linear; total time=   1.0s\n",
      "[CV] END C=0.01, coef0=1, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.01, coef0=1, degree=3, gamma=auto, kernel=linear; total time=   0.6s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.01, kernel=linear; total time=   9.9s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.01, kernel=linear; total time=   9.9s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.01, kernel=linear; total time=   9.4s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.01, kernel=linear; total time=  23.3s\n",
      "[CV] END C=100, coef0=1, degree=5, gamma=0.01, kernel=linear; total time=  10.3s\n",
      "[CV] END .C=0.01, coef0=1, degree=2, gamma=0.01, kernel=poly; total time=   1.2s\n",
      "[CV] END .C=0.01, coef0=1, degree=2, gamma=0.01, kernel=poly; total time=   1.7s\n",
      "[CV] END .C=0.01, coef0=1, degree=2, gamma=0.01, kernel=poly; total time=   1.4s\n",
      "[CV] END .C=0.01, coef0=1, degree=2, gamma=0.01, kernel=poly; total time=   1.0s\n",
      "[CV] END .C=0.01, coef0=1, degree=2, gamma=0.01, kernel=poly; total time=   1.1s\n",
      "[CV] END ..C=100, coef0=0, degree=2, gamma=auto, kernel=poly; total time=   9.2s\n",
      "[CV] END ..C=100, coef0=0, degree=2, gamma=auto, kernel=poly; total time=   5.9s\n",
      "[CV] END ..C=100, coef0=0, degree=2, gamma=auto, kernel=poly; total time=  11.1s\n",
      "[CV] END ..C=100, coef0=0, degree=2, gamma=auto, kernel=poly; total time=   9.3s\n",
      "[CV] END ..C=100, coef0=0, degree=2, gamma=auto, kernel=poly; total time=   6.0s\n",
      "[CV] END .C=0.01, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   1.8s\n",
      "[CV] END .C=0.01, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   1.8s\n",
      "[CV] END .C=0.01, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   1.7s\n",
      "[CV] END .C=0.01, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   1.9s\n",
      "[CV] END .C=0.01, coef0=-1, degree=3, gamma=auto, kernel=rbf; total time=   1.8s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.8s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.7s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.7s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ...C=10, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.7s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=auto, kernel=poly; total time=   3.0s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=auto, kernel=poly; total time=   3.6s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=auto, kernel=poly; total time=   2.7s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=auto, kernel=poly; total time=   2.7s\n",
      "[CV] END ...C=10, coef0=1, degree=3, gamma=auto, kernel=poly; total time=   2.8s\n",
      "[CV] END .C=1, coef0=1, degree=3, gamma=0.001, kernel=linear; total time=   0.9s\n",
      "[CV] END .C=1, coef0=1, degree=3, gamma=0.001, kernel=linear; total time=   1.1s\n",
      "[CV] END .C=1, coef0=1, degree=3, gamma=0.001, kernel=linear; total time=   0.9s\n",
      "[CV] END .C=1, coef0=1, degree=3, gamma=0.001, kernel=linear; total time=   1.0s\n",
      "[CV] END .C=1, coef0=1, degree=3, gamma=0.001, kernel=linear; total time=   1.1s\n",
      "[CV] END C=0.1, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   0.9s\n",
      "[CV] END C=0.1, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END C=1, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END C=1, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.3s\n",
      "[CV] END C=1, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END C=1, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.2s\n",
      "[CV] END C=1, coef0=1, degree=2, gamma=scale, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END .C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   1.6s\n",
      "[CV] END .C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   1.6s\n",
      "[CV] END .C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   1.5s\n",
      "[CV] END .C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   1.6s\n",
      "[CV] END .C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=rbf; total time=   1.6s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   0.7s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   0.7s\n",
      "[CV] END C=0.1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   0.7s\n",
      "[CV] END ..C=0.1, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ..C=0.1, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ..C=0.1, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.5s\n",
      "[CV] END ..C=0.1, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.7s\n",
      "[CV] END ..C=0.1, coef0=-1, degree=5, gamma=0.1, kernel=poly; total time=   0.7s\n",
      "[CV] END ...C=100, coef0=-1, degree=5, gamma=0.1, kernel=rbf; total time=   2.0s\n",
      "[CV] END ...C=100, coef0=-1, degree=5, gamma=0.1, kernel=rbf; total time=   2.4s\n",
      "[CV] END ...C=100, coef0=-1, degree=5, gamma=0.1, kernel=rbf; total time=   2.3s\n",
      "[CV] END ...C=100, coef0=-1, degree=5, gamma=0.1, kernel=rbf; total time=   2.3s\n",
      "[CV] END ...C=100, coef0=-1, degree=5, gamma=0.1, kernel=rbf; total time=   2.3s\n",
      "[CV] END ..C=0.1, coef0=0, degree=5, gamma=auto, kernel=poly; total time=   1.3s\n",
      "[CV] END ..C=0.1, coef0=0, degree=5, gamma=auto, kernel=poly; total time=   0.9s\n",
      "[CV] END ..C=0.1, coef0=0, degree=5, gamma=auto, kernel=poly; total time=   1.2s\n",
      "[CV] END ..C=0.1, coef0=0, degree=5, gamma=auto, kernel=poly; total time=   0.9s\n",
      "[CV] END ..C=0.1, coef0=0, degree=5, gamma=auto, kernel=poly; total time=   1.2s\n",
      "[CV] END ...C=1, coef0=-1, degree=3, gamma=auto, kernel=poly; total time=   0.6s\n",
      "[CV] END ...C=1, coef0=-1, degree=3, gamma=auto, kernel=poly; total time=   0.6s\n",
      "[CV] END ...C=1, coef0=-1, degree=3, gamma=auto, kernel=poly; total time=   0.7s\n",
      "[CV] END ...C=1, coef0=-1, degree=3, gamma=auto, kernel=poly; total time=   0.7s\n",
      "[CV] END ...C=1, coef0=-1, degree=3, gamma=auto, kernel=poly; total time=   0.5s\n",
      "[CV] END ..C=1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   1.0s\n",
      "[CV] END ..C=1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   1.0s\n",
      "[CV] END ..C=1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   1.1s\n",
      "[CV] END ..C=1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   1.1s\n",
      "[CV] END ..C=1, coef0=-1, degree=2, gamma=0.1, kernel=linear; total time=   1.0s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=5, gamma=1, kernel=poly; total time=   1.4s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=5, gamma=1, kernel=poly; total time=   2.3s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=5, gamma=1, kernel=poly; total time=   1.6s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=5, gamma=1, kernel=poly; total time=   0.8s\n",
      "[CV] END ....C=0.1, coef0=-1, degree=5, gamma=1, kernel=poly; total time=   1.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   0.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   0.7s\n",
      "[CV] END C=0.01, coef0=-1, degree=5, gamma=0.01, kernel=poly; total time=   0.8s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=auto, kernel=rbf; total time=   1.3s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=auto, kernel=rbf; total time=   1.2s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=auto, kernel=rbf; total time=   1.3s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=auto, kernel=rbf; total time=   1.3s\n",
      "[CV] END ....C=1, coef0=-1, degree=2, gamma=auto, kernel=rbf; total time=   1.3s\n",
      "[CV] END .C=10, coef0=1, degree=3, gamma=0.01, kernel=linear; total time=   2.0s\n",
      "[CV] END .C=10, coef0=1, degree=3, gamma=0.01, kernel=linear; total time=   1.7s\n",
      "[CV] END .C=10, coef0=1, degree=3, gamma=0.01, kernel=linear; total time=   1.8s\n",
      "[CV] END .C=10, coef0=1, degree=3, gamma=0.01, kernel=linear; total time=   1.7s\n",
      "[CV] END .C=10, coef0=1, degree=3, gamma=0.01, kernel=linear; total time=   1.8s\n",
      "[CV] END C=100, coef0=0, degree=3, gamma=0.001, kernel=linear; total time=   7.8s\n",
      "[CV] END C=100, coef0=0, degree=3, gamma=0.001, kernel=linear; total time=   9.3s\n",
      "[CV] END C=100, coef0=0, degree=3, gamma=0.001, kernel=linear; total time=   7.5s\n",
      "[CV] END C=100, coef0=0, degree=3, gamma=0.001, kernel=linear; total time=  19.9s\n",
      "[CV] END C=100, coef0=0, degree=3, gamma=0.001, kernel=linear; total time=   9.5s\n",
      "[CV] END C=100, coef0=-1, degree=5, gamma=0.1, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END C=100, coef0=-1, degree=5, gamma=0.1, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END C=100, coef0=-1, degree=5, gamma=0.1, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END C=100, coef0=-1, degree=5, gamma=0.1, kernel=sigmoid; total time=   1.3s\n",
      "[CV] END C=100, coef0=-1, degree=5, gamma=0.1, kernel=sigmoid; total time=   1.0s\n",
      "[CV] END ..C=0.01, coef0=1, degree=3, gamma=0.01, kernel=rbf; total time=   1.8s\n",
      "[CV] END ..C=0.01, coef0=1, degree=3, gamma=0.01, kernel=rbf; total time=   1.6s\n",
      "[CV] END ..C=0.01, coef0=1, degree=3, gamma=0.01, kernel=rbf; total time=   1.7s\n",
      "[CV] END ..C=0.01, coef0=1, degree=3, gamma=0.01, kernel=rbf; total time=   1.5s\n",
      "[CV] END ..C=0.01, coef0=1, degree=3, gamma=0.01, kernel=rbf; total time=   1.5s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=auto, kernel=poly; total time=   0.4s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=auto, kernel=poly; total time=   0.3s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=auto, kernel=poly; total time=   0.6s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=auto, kernel=poly; total time=   0.4s\n",
      "[CV] END C=0.01, coef0=-1, degree=4, gamma=auto, kernel=poly; total time=   1.4s\n",
      "[CV] END C=0.01, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=0.01, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   1.9s\n",
      "[CV] END C=0.01, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.01, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=scale, kernel=linear; total time=   1.3s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=scale, kernel=linear; total time=   1.3s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=scale, kernel=linear; total time=   1.3s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=scale, kernel=linear; total time=   1.0s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=scale, kernel=linear; total time=   0.8s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   1.7s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   2.0s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   1.7s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   2.4s\n",
      "[CV] END .C=0.1, coef0=-1, degree=2, gamma=1, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=scale, kernel=rbf; total time=   1.4s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=scale, kernel=rbf; total time=   1.3s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=scale, kernel=rbf; total time=   1.7s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=scale, kernel=rbf; total time=   1.9s\n",
      "[CV] END ...C=10, coef0=0, degree=4, gamma=scale, kernel=rbf; total time=   1.4s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=scale, kernel=rbf; total time=   1.5s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=scale, kernel=rbf; total time=   1.5s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=scale, kernel=rbf; total time=   1.5s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=scale, kernel=rbf; total time=   1.4s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=scale, kernel=rbf; total time=   2.2s\n",
      "[CV] END C=0.1, coef0=1, degree=5, gamma=scale, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.1, coef0=1, degree=5, gamma=scale, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=0.1, coef0=1, degree=5, gamma=scale, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END C=0.1, coef0=1, degree=5, gamma=scale, kernel=sigmoid; total time=   2.0s\n",
      "[CV] END C=0.1, coef0=1, degree=5, gamma=scale, kernel=sigmoid; total time=   2.0s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=1, kernel=sigmoid; total time=   2.3s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=1, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=1, kernel=sigmoid; total time=   1.9s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=1, kernel=sigmoid; total time=   1.5s\n",
      "[CV] END ..C=0.1, coef0=0, degree=3, gamma=1, kernel=sigmoid; total time=   1.8s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.5s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.5s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.001, kernel=sigmoid; total time=   1.1s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=linear; total time=   0.7s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=linear; total time=   0.6s\n",
      "[CV] END C=0.1, coef0=0, degree=3, gamma=0.01, kernel=linear; total time=   0.6s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   8.6s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=  10.8s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   7.9s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=  19.4s\n",
      "[CV] END C=100, coef0=-1, degree=4, gamma=scale, kernel=linear; total time=   9.0s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   1.3s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   1.4s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   1.6s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   1.5s\n",
      "[CV] END ...C=10, coef0=0, degree=5, gamma=0.001, kernel=rbf; total time=   1.1s\n",
      "[CV] END C=0.01, coef0=0, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.2s\n",
      "[CV] END C=0.01, coef0=0, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.9s\n",
      "[CV] END C=0.01, coef0=0, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.7s\n",
      "[CV] END C=0.01, coef0=0, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END C=0.01, coef0=0, degree=5, gamma=0.01, kernel=sigmoid; total time=   1.2s\n",
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.001, 'degree': 5, 'coef0': 1, 'C': 100}\n",
      "Test Accuracy: 0.6812196812196812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1, 'scale', 'auto'],\n",
    "    'degree': [2, 3, 4, 5],  # Only used by 'poly' kernel\n",
    "    'coef0': [-1, 0, 1],    # Used by 'poly' and 'sigmoid' kernels\n",
    "}\n",
    "\n",
    "# Using RandomizedSearchCV with increased iterations\n",
    "random_search = RandomizedSearchCV(SVC(), param_distributions=param_grid, \n",
    "                                   n_iter=100, verbose=2, cv=5, n_jobs=1, \n",
    "                                   random_state=42)\n",
    "\n",
    "# Using a larger subset of the data for hyperparameter tuning\n",
    "subset_indices = np.random.choice(len(X_train_scaled), 5000, replace=False)\n",
    "X_subset = X_train_scaled[subset_indices]\n",
    "y_subset = y_train.iloc[subset_indices]\n",
    "\n",
    "random_search.fit(X_subset, y_subset)\n",
    "\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "\n",
    "# Evaluate on test data\n",
    "accuracy = random_search.best_estimator_.score(X_test_scaled, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, coef0=1, degree=5, gamma=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, coef0=1, degree=5, gamma=0.001)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, coef0=1, degree=5, gamma=0.001)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(kernel='rbf', gamma=0.001, degree=5, coef0=1, C=100)\n",
    "\n",
    "svc_model.fit(X_sme_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svc_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[561, 234],\n",
       "       [228, 420]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       795\n",
      "           1       0.64      0.65      0.65       648\n",
      "\n",
      "    accuracy                           0.68      1443\n",
      "   macro avg       0.68      0.68      0.68      1443\n",
      "weighted avg       0.68      0.68      0.68      1443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       811\n",
      "           1       0.63      0.66      0.64       632\n",
      "\n",
      "    accuracy                           0.68      1443\n",
      "   macro avg       0.68      0.68      0.68      1443\n",
      "weighted avg       0.68      0.68      0.68      1443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model.fit(X_train, y_train)\n",
    "pred = svc_model.predict(X_test)\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Caucasian Samples:\n",
      "[[253  57]\n",
      " [ 92 103]]\n",
      "\n",
      "Confusion Matrix for African-American Samples:\n",
      "[[207 134]\n",
      " [106 284]]\n"
     ]
    }
   ],
   "source": [
    "# Subset the true labels and predictions for Caucasian samples\n",
    "y_test_caucasian = y_test[X_test['race_Caucasian'] == 1]\n",
    "y_pred_caucasian = pred[X_test['race_Caucasian'] == 1]\n",
    "\n",
    "# Subset the true labels and predictions for African-American samples\n",
    "y_test_aa = y_test[X_test['race_African-American'] == 1]\n",
    "y_pred_aa = pred[X_test['race_African-American'] == 1]\n",
    "\n",
    "# Compute confusion matrices\n",
    "confusion_matrix_caucasian = confusion_matrix(y_test_caucasian, y_pred_caucasian)\n",
    "confusion_matrix_aa = confusion_matrix(y_test_aa, y_pred_aa)\n",
    "\n",
    "print(\"Confusion Matrix for Caucasian Samples:\")\n",
    "print(confusion_matrix_caucasian)\n",
    "\n",
    "print(\"\\nConfusion Matrix for African-American Samples:\")\n",
    "print(confusion_matrix_aa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_df = pd.read_csv(url)\n",
    "\n",
    "fair_df = fair_df[['id', 'sex', 'age_cat', 'race', 'juv_fel_count',\n",
    "       'juv_misd_count', 'priors_count', 'c_charge_degree', \n",
    "       'is_recid', 'decile_score.1']]\n",
    "dummy_cols = ['sex','age_cat','c_charge_degree'] \n",
    "\n",
    "fair_df = pd.get_dummies(fair_df, columns=dummy_cols)\n",
    "\n",
    "fair_df = fair_df.drop(columns=[\"sex_Female\", \"c_charge_degree_M\"])\n",
    "X = fair_df.drop(columns=[\"is_recid\", \"race\"])\n",
    "fair_dff = fair_df.set_index('id')\n",
    "y = fair_df[\"is_recid\"]\n",
    "race = df[\"race\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, class_weight=&#x27;balanced&#x27;, max_iter=10000,\n",
       "                   solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, class_weight=&#x27;balanced&#x27;, max_iter=10000,\n",
       "                   solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight='balanced', max_iter=10000,\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.01, class_weight='balanced', max_iter=10000, penalty='l2', solver='saga')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.TruePositiveRateParity object at 0x000002A482BDD280&gt;,\n",
       "                      estimator=LogisticRegression(max_iter=10000),\n",
       "                      nu=0.002753280121250147)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExponentiatedGradient</label><div class=\"sk-toggleable__content\"><pre>ExponentiatedGradient(constraints=&lt;fairlearn.reductions._moments.utility_parity.TruePositiveRateParity object at 0x000002A482BDD280&gt;,\n",
       "                      estimator=LogisticRegression(max_iter=10000),\n",
       "                      nu=0.002753280121250147)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExponentiatedGradient(constraints=<fairlearn.reductions._moments.utility_parity.TruePositiveRateParity object at 0x000002A482BDD280>,\n",
       "                      estimator=LogisticRegression(max_iter=10000),\n",
       "                      nu=0.002753280121250147)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient, TruePositiveRateParity\n",
    "\n",
    "# Create the fairness constraint. In this case, it's true positive rate parity.\n",
    "constraint = TruePositiveRateParity()\n",
    "\n",
    "# Train the ExponentiatedGradient model.\n",
    "clf_mitigated = ExponentiatedGradient(\n",
    "    estimator=LogisticRegression(max_iter=10000),\n",
    "    constraints=constraint\n",
    ")\n",
    "clf_mitigated.fit(X, y, sensitive_features=race)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model Results:\n",
      "                  accuracy  precision    recall  f1_score\n",
      "race                                                     \n",
      "African-American  0.628517   0.637609  0.754420  0.691114\n",
      "Asian             0.812500   0.692308  0.818182  0.750000\n",
      "Caucasian         0.626732   0.546462  0.625366  0.583258\n",
      "Hispanic          0.612245   0.496503  0.579592  0.534840\n",
      "Native American   0.666667   0.692308  0.818182  0.750000\n",
      "Other             0.628647   0.509434  0.566434  0.536424\n",
      "\n",
      "Mitigated Model Results:\n",
      "                  accuracy  precision    recall  f1_score\n",
      "race                                                     \n",
      "African-American  0.457792   0.603896  0.045678  0.084932\n",
      "Asian             0.656250   0.000000  0.000000  0.000000\n",
      "Caucasian         0.583537   0.521739  0.035122  0.065814\n",
      "Hispanic          0.612245   0.454545  0.040816  0.074906\n",
      "Native American   0.444444   1.000000  0.090909  0.166667\n",
      "Other             0.628647   0.714286  0.034965  0.066667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\cainhurst\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Predict with the original and mitigated models\n",
    "y_pred = clf.predict(X)\n",
    "y_pred_mitigated = clf_mitigated.predict(X)\n",
    "\n",
    "# Define the metrics\n",
    "metrics_dict = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1_score': f1_score,\n",
    "    # Uncomment the next line if you have probability predictions for roc_auc\n",
    "    # 'roc_auc': roc_auc_score  \n",
    "}\n",
    "\n",
    "# Assess performance\n",
    "# Evaluate the initial model\n",
    "metric_frame_initial = MetricFrame(\n",
    "    metrics=metrics_dict,\n",
    "    y_true=y,\n",
    "    y_pred=y_pred,\n",
    "    sensitive_features=race\n",
    ")\n",
    "\n",
    "# Evaluate the mitigated model\n",
    "metric_frame_mitigated = MetricFrame(\n",
    "    metrics=metrics_dict,\n",
    "    y_true=y,\n",
    "    y_pred=y_pred_mitigated,\n",
    "    sensitive_features=race\n",
    ")\n",
    "\n",
    "print(\"Initial Model Results:\")\n",
    "print(metric_frame_initial.by_group)\n",
    "print(\"\\nMitigated Model Results:\")\n",
    "print(metric_frame_mitigated.by_group)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
